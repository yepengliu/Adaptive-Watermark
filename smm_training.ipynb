{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "semantic_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "semantic_model.to(device)\n",
    "data_name = 'embedding-data/sentence-compression'\n",
    "original_data = load_dataset(data_name)\n",
    "\n",
    "orig_text = list(item[0] for item in original_data['train']['set'][:10000])\n",
    "comp_text = list(item[1] for item in original_data['train']['set'][:10000])\n",
    "\n",
    "orig_data = Dataset.from_dict({'text': orig_text})\n",
    "comp_data = Dataset.from_dict({'text': comp_text})\n",
    "\n",
    "orig_embedding_list = []\n",
    "comp_embedding_list = []\n",
    "\n",
    "for i in tqdm(range(orig_data.num_rows)):\n",
    "    orig_embedding_list.append(semantic_model.encode(orig_data[i]['text'], convert_to_tensor=True).unsqueeze(0).cpu().numpy())\n",
    "    comp_embedding_list.append(semantic_model.encode(comp_data[i]['text'], convert_to_tensor=True).unsqueeze(0).cpu().numpy())\n",
    "\n",
    "orig_embeddings = np.vstack(orig_embedding_list)\n",
    "comp_embeddings = np.vstack(comp_embedding_list)\n",
    "\n",
    "np.savetxt(os.path.join('m', 'orig_embeddings_sc.text'), orig_embeddings, delimiter=\" \")\n",
    "np.savetxt(os.path.join('m', 'comp_embeddings_sc.text'), comp_embeddings, delimiter=\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, ConcatDataset\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.fc = nn.Linear(dim, dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        out = self.relu(out)\n",
    "        out = out + x \n",
    "        return out\n",
    "\n",
    "class TransformModel(nn.Module):\n",
    "    def __init__(self, num_layers=4, input_dim=768, hidden_dim=512, output_dim=384):\n",
    "        super(TransformModel, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        \n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(ResidualBlock(hidden_dim))\n",
    "\n",
    "        self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers)):\n",
    "            x = self.layers[i](x)\n",
    "        return x\n",
    "\n",
    "class VectorDataset(Dataset):\n",
    "    def __init__(self, vectors):\n",
    "        self.vectors = vectors\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.vectors)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.vectors[idx]\n",
    "\n",
    "\n",
    "def sequence_similarity(x, y):\n",
    "    # euclidean distance\n",
    "    matches = torch.sqrt(torch.sum((x-y)**2, dim=-1))\n",
    "    return matches\n",
    "\n",
    "def sign_loss(x, factor):\n",
    "    smooth_sign = torch.tanh(x*factor)\n",
    "    row = torch.abs(torch.mean(torch.mean(smooth_sign, dim=0)))\n",
    "    col = torch.abs(torch.mean(torch.mean(smooth_sign, dim=1)))\n",
    "    return (row + col)/2\n",
    "\n",
    "def loss_fn(\n",
    "        output_a, \n",
    "        output_b, \n",
    "        input_a, \n",
    "        input_b, \n",
    "        output_a_hat, \n",
    "        lambda_1,\n",
    "        lambda_2,\n",
    "        lambda_3):\n",
    "    \n",
    "    s = sequence_similarity(input_a, input_b)\n",
    "    t_s = sequence_similarity(output_a, output_b)\n",
    "\n",
    "    min_orig, max_orig, min_new, max_new = 0, 2, -2, 4\n",
    "    s = (s - min_orig) / (max_orig - min_orig) * (max_new - min_new) + min_new\n",
    "\n",
    "    loss_1 = torch.abs(s - t_s).mean()\n",
    "    loss_2 = (sign_loss(output_a, 1000) + sign_loss(output_b, 1000))/2\n",
    "    loss_3 = torch.abs(sequence_similarity(output_a, output_a_hat)).mean()\n",
    "    \n",
    "    total_loss = lambda_1*loss_1 + lambda_2*loss_2 + lambda_3*loss_3\n",
    "    return total_loss, loss_1, loss_2, loss_3\n",
    "\n",
    "\n",
    "def parser(args=None):\n",
    "    parser = argparse.ArgumentParser(description=\"Train watermark model\")\n",
    "    parser.add_argument(\"--orig_input_file\", type=str, default=\"orig_embeddings_sc.text\")\n",
    "    parser.add_argument(\"--comp_input_file\", type=str, default=\"comp_embeddings_sc.text\")\n",
    "    parser.add_argument(\"--output_model\", type=str, default=\"transform_model.pth\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=1000)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-5)\n",
    "    parser.add_argument(\"--input_dim\", type=int, default=768)\n",
    "\n",
    "    args = parser.parse_args(args=args)\n",
    "    return args\n",
    "\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "MODEL_DIR = \"model\"\n",
    "\n",
    "args = parser(['--epochs', '500',\n",
    "               '--lr', '1e-5',\n",
    "               '--output_model', 'transform_model_1.pth'])\n",
    "print(args)\n",
    "\n",
    "\n",
    "orig_embedding_file = os.path.join(DATA_DIR, args.orig_input_file)\n",
    "comp_embedding_file = os.path.join(DATA_DIR, args.comp_input_file)\n",
    "orig_embedding_data = np.loadtxt(orig_embedding_file)\n",
    "comp_embedding_data = np.loadtxt(comp_embedding_file)\n",
    "\n",
    "orig_data_1 = torch.tensor(orig_embedding_data[:5000], device='cuda', dtype=torch.float32)\n",
    "orig_data_2 = torch.tensor(orig_embedding_data[5000:], device='cuda', dtype=torch.float32)\n",
    "comp_data = torch.tensor(comp_embedding_data[:5000], device='cuda', dtype=torch.float32)\n",
    "\n",
    "orig_dataset_1 = VectorDataset(orig_data_1)\n",
    "orig_dataset_2 = VectorDataset(orig_data_2)\n",
    "comp_dataset = VectorDataset(comp_data)\n",
    "\n",
    "orig_dataloader_1 = DataLoader(orig_dataset_1, batch_size=128, shuffle=False)\n",
    "orig_dataloader_2 = DataLoader(orig_dataset_2, batch_size=128, shuffle=False)\n",
    "comp_dataloader = DataLoader(comp_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "model = TransformModel(input_dim=args.input_dim).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=0.2)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.1)\n",
    "\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    orig_iter_1 = iter(orig_dataloader_1)\n",
    "    orig_iter_2 = iter(orig_dataloader_2)\n",
    "    comp_iter = iter(comp_dataloader)\n",
    "\n",
    "    for _ in range(len(orig_dataloader_1)):\n",
    "        input_a = next(orig_iter_1).to(device)\n",
    "        input_b = next(orig_iter_2).to(device)\n",
    "        input_c = next(comp_iter).to(device)\n",
    "\n",
    "        output_a = model(input_a)\n",
    "        output_b = model(input_b)\n",
    "        output_c = model(input_c)\n",
    "\n",
    "        loss, loss_1, loss_2, loss_3 = loss_fn(output_a, output_b, input_a, input_b, output_c, 1, 1, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if _ % 100 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{args.epochs}], Step [{_ + 1}/{len(orig_dataloader_1)}], Loss: {loss.item()}\")\n",
    "\n",
    "model_path = os.path.join(MODEL_DIR, args.output_model)\n",
    "torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
